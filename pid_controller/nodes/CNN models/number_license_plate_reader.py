#! /usr/bin/env python

"""Number License Plate Reader.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ybWQTp75tzTvMCgJggxPWcv_cUisnLRp
"""

import math
import numpy as np
import re
import cv2
from collections import Counter
from matplotlib import pyplot as plt
from PIL import Image

"""# Load Data"""

PATH = "/content/drive/My Drive/Shared ENPH 353/License Plate CNN/Competition CNNs/Cropped and Labelled License Plates"

def files_in_folder(folder_path):
  '''
  Returns a list of strings where each entry is a file in the folder_path.
  
  Parameters
  ----------
  
  folder_path : str
     A string to folder for which the file listing is returned.
     
  '''
  files_A = !ls "{folder_path}"
  # The files when listed from Google Drive have a particular format. They are
  # grouped in sets of 4 and have spaces and tabs as delimiters.
  
  # Split the string listing sets of 4 files by tab and space and remove any 
  # empty splits.
  files_B = [list(filter(None, re.split('\t|\s', files))) for files in files_A]
  
  # Concatenate all splits into a single sorted list
  files_C = []
  for element in files_B:
    files_C = files_C + element
  files_C.sort()
  
  return files_C

files = files_in_folder(PATH)
folder = PATH

i = np.random.random_integers(0,100)
path = PATH + '/' + files[i]
img = cv2.imread(path)
h,w,d = img.shape
sec_w = int(w/4)
print(h)
print(w)

# Load the images
imgset = np.array(
    [[np.array(Image.open(f'{PATH}/{file}'))[:, sec_w*i:sec_w*(i+1)], file[i]] for file in files
     for i in range(2,4)])

print("Loaded {:} images from folder:\n{}".format(imgset.shape[0], folder))

#Possibly crop white space out of images
#First images cut first 7
#Second images cut last 7
#Third images cut first 7
#Fourth images cut last 7

i = 0
while(i < 468):
  imgset[i,0] = imgset[i,0][:,7:25]
  imgset[i + 1,0] = imgset[i + 1,0][:,0:18]
  i = i + 2

i = np.random.randint(0,437)
plt.imshow(imgset[i,0])
#test cropping

"""# Generate Datasets"""

# Generate X and Y datasets
np.random.shuffle(imgset)
X_dataset_orig = np.array([data[0] for data in imgset])
Y_dataset_orig = np.array([data[1] for data in imgset])

#Use numbers 0 to 9 for numbers and 10 to 35 for letters
def value(char):
    return char

#Find the character from the value
def char(val):
    return val

NUMBER_OF_LABELS = 10
CONFIDENCE_THRESHOLD = 0.01

def convert_to_one_hot(Y, C):
    Y = np.reshape(Y,(-1))
    Y1 = np.zeros((Y.shape[0], NUMBER_OF_LABELS))
    for c in range(Y1.shape[0]):
      Y1[c,int(value(Y[c]))] = 1
    return Y1
  
# Normalize X (images) dataset
X_dataset = X_dataset_orig/255.

# Convert Y dataset to one-hot encoding
Y_dataset = convert_to_one_hot(Y_dataset_orig, NUMBER_OF_LABELS)

i = np.random.random_integers(0,436)
print(Y_dataset[i])
plt.imshow(X_dataset[i])

VALIDATION_SPLIT = 0.2

print("Total examples: {:d}\nTraining examples: {:d}\nTest examples: {:d}".
      format(X_dataset.shape[0],
             math.ceil(X_dataset.shape[0] * (1-VALIDATION_SPLIT)),
             math.floor(X_dataset.shape[0] * VALIDATION_SPLIT)))
print("X shape: " + str(X_dataset.shape))
print("Y shape: " + str(Y_dataset.shape))

"""# Training CNN"""

from keras import layers
from keras import models
from keras import optimizers

from keras.utils import plot_model
from keras import backend

from keras import models

from sklearn.metrics import confusion_matrix, plot_confusion_matrix

# Source: https://stackoverflow.com/questions/63435679
def reset_weights(model):
  for ix, layer in enumerate(model.layers):
      if (hasattr(model.layers[ix], 'kernel_initializer') and 
          hasattr(model.layers[ix], 'bias_initializer')):
          weight_initializer = model.layers[ix].kernel_initializer
          bias_initializer = model.layers[ix].bias_initializer

          old_weights, old_biases = model.layers[ix].get_weights()

          model.layers[ix].set_weights([
              weight_initializer(shape=old_weights.shape),
              bias_initializer(shape=len(old_biases))])

conv_model = models.Sequential()
conv_model.add(layers.Conv2D(8, (3, 3), activation='relu',
                             input_shape=(20, 18, 3)))
conv_model.add(layers.MaxPooling2D((2, 2)))
conv_model.add(layers.Conv2D(16, (3, 3), activation='relu'))
conv_model.add(layers.MaxPooling2D((2, 2)))
conv_model.add(layers.Flatten())
conv_model.add(layers.Dropout(0.5))
conv_model.add(layers.Dense(80, activation='relu'))
conv_model.add(layers.Dense(50, activation='relu'))
conv_model.add(layers.Dense(10, activation='softmax'))

conv_model.summary()

LEARNING_RATE = 7e-4
conv_model.compile(loss='categorical_crossentropy',
                   optimizer=optimizers.RMSprop(lr=LEARNING_RATE),
                   metrics=['acc'])

reset_weights(conv_model)
history_conv = conv_model.fit(X_dataset, Y_dataset, 
                              validation_split=VALIDATION_SPLIT, 
                              epochs=100, 
                              batch_size=4)

plt.plot(history_conv.history['loss'])
plt.plot(history_conv.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train loss', 'val loss'], loc='upper left')
plt.show()

plt.plot(history_conv.history['acc'])
plt.plot(history_conv.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy (%)')
plt.xlabel('epoch')
plt.legend(['train accuracy', 'val accuracy'], loc='upper left')
plt.show()

# Display images in the training data set. 
def displayImage(index):
  img = X_dataset[index]
  
  img_aug = np.expand_dims(img, axis=0)
  y_predict = conv_model.predict(img_aug)[0]

  i = 0
  for y in Y_dataset[index]:
    if(y == 1):
      true = i
    i = i+1
  predict = np.argmax(y_predict)
  num = y_predict[predict]
  
  plt.imshow(img)  
  caption = ("Truth: {}".format(char(true))+
             "\nPredicted: {} at {:.2}".
             format(char(predict), num))
  plt.text(0.5, 0.5, caption, 
           color='orange', fontsize = 16,
           horizontalalignment='left', verticalalignment='bottom')


# interact(displayImage, 
#         index=ipywidgets.IntSlider(min=0, max=X_dataset_orig.shape[0],
#                                    step=1, value=10))
displayImage(np.random.random_integers(0,463))

import pandas as pd
import seaborn as sn

label = '0123456789'
y_pred = conv_model.predict(X_dataset)

def get_char(position):
  if position < 26:
     return chr(position + ord('A'))
  else:
    return chr(position - 26 + ord('0'))

y_pred_chars = [[get_char(np.argmax(pred))] for pred in y_pred]

y_true_chars = [[get_char(np.where(y_true == 1)[0])] for y_true in Y_dataset]


cm = confusion_matrix(y_true_chars, y_pred_chars)

df_cm = pd.DataFrame(cm, index = [i for i in label],
                  columns = [i for i in label])
plt.figure(figsize = (10,7))
sn.heatmap(df_cm, annot=True)

#Saving model
models.save_model(conv_model,'/home/fizzer/ros_ws/src/Competition_Package/pid_controller/nodes/CNN models/NumberModel')

"""# Displaying Images"""

from ipywidgets import interact
import ipywidgets as ipywidgets

# Display images in the training data set. 
def displayImage(index):
  plt.imshow(X_dataset[index])


displayImage(4)
# interact(displayImage, 
#         index=ipywidgets.IntSlider(min=0, max=X_dataset_orig.shape[0],
#                                    step=1, value=10))